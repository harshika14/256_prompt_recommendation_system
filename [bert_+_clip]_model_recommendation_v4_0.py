# -*- coding: utf-8 -*-
"""[Bert + Clip] Model recommendation V4.0

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1frYyDSF7pwxGc38EOQr5vZ5adH6oc9f6

# Author : Kapil Wanaskar
# San Jose State University
# Student ID: 0166498890
"""

import pandas as pd
import numpy as np

!pip install Pillow

!pip install datasets

import numpy as np
from datasets import load_dataset

# Load the dataset with the `2m_first_5k` subset
# we need to download dataset every time, so do not use random!
# use '2m_first_5k' for the consistency among the models
# for me (Hyelim), it takes about 3 min to download
dataset = load_dataset('poloclub/diffusiondb', '2m_first_5k')

my_5k_data = dataset['train']
df = pd.DataFrame( my_5k_data ) # this will take about 3 min too
df.head()

df['id'] = df.index
first_column = df.pop('id')
df.insert(0, 'id', first_column)
df.head()

image = df['image'][2]
image

image_random = df['image'][3845]
image_random

"""# Install dependencies"""

!pip install emoji
!pip install emot
!pip install clean-text[gpl]
!pip install 
!pip install cleantext
!pip install plotly

"""## Prompt preprocessing

This code will open a file upload dialog. Select the 'Emoji_Dict.p' file from your local system to upload it.

# PROMPT PROCESSING
"""

import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_distances
import re
import pickle
import emoji
import emot.emo_unicode
from cleantext import clean
import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
import string

# Extract 'id' and 'prompt' columns
prompt = df[['id', 'prompt']]
prompt.head()

# Step (a) Convert emoji to word(s)
with open('Emoji_Dict.p', 'rb') as fp:
    Emoji_Dict = pickle.load(fp)
Emoji_Dict = {v: k for k, v in Emoji_Dict.items()}

import emoji

def convert_emojis_to_word_pd(row):
    if bool(emoji.emoji_count(row[1])):
        temp = row[1]
        temp = emoji.demojize(temp)
        temp = temp.replace(":", " ")
        return temp
    else:
        return row[1]

prompt['no_emojis'] = prompt.apply(convert_emojis_to_word_pd, axis = 1)


# Step (b) Remove stop words and stemming
nltk.download('stopwords')
nltk.download('punkt')

stopwords = stopwords.words('english')
stemmer = nltk.stem.PorterStemmer()

def remove_stopwords_stemming(row):
  special_characters = set(string.punctuation)
  text = ''.join(ch for ch in row[2] if ch not in special_characters and not ch.isnumeric())
  tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent) if word.lower() not in stopwords]
  after_stemming = [stemmer.stem(token) for token in tokens]
  return ' '.join(after_stemming)

prompt['after_stemming'] = prompt.apply(remove_stopwords_stemming, axis = 1)

# Step (d) Add word count column
def word_count(row):
  temp = row[3]
  return len([s for s in temp.split(' ') if not s.isnumeric()])

prompt['word_count'] = prompt.apply(word_count, axis = 1)

# Step (e) Delete rows that have only numerical
index_to_drop = prompt[prompt['after_stemming'] == ''].index
prompt.drop(index_to_drop , inplace=True)

# Final cleaned DataFrame
df2 = prompt[prompt['word_count'] >= 2]

# Load pre-trained Word2Vec model
import gensim.downloader as api
word2vec_model = api.load("word2vec-google-news-300")

# Calculate embeddings for all prompts
df2['embedding'] = df2['after_stemming'].apply(lambda prompt: np.mean([word2vec_model[word] for word in prompt.split() if word in word2vec_model], axis=0))

# Remove rows with empty embeddings
df2 = df2[df2['embedding'].apply(lambda x: x.size != 1)]
df2

# Processed PROMPT dataset
df_processed_prompt = df2 
df_processed_prompt

# Step 1: merge "image" + "processed_prompt" datasets
df = pd.concat([df_processed_prompt, df['image']], axis=1)
df['prompt'] = df_processed_prompt['after_stemming']
df = df.dropna(subset=['prompt'])
df = df[['prompt', 'image']]
df

image = df['image'][2]
image

example = 712
df['prompt'][example]

df['image'][example]

# "similar_prompts" code:
import numpy as np
from PIL import Image

def similar_prompts(topN, sim_mat, ID):
    """
    --- Inputs ---
    topN: the number of prompts to be recommended
    sim_mat: similarity matrix. This should be a square matrix
    ID: id of the prompt
    --- Output ---
    Input prompt df['prompt'][random] and input image df['prompt'][random]
    topN similar prompts
    """
    temp_prompt = sim_mat[ID]
    index_after_sort = np.argsort(temp_prompt)[::-1]
    index_after_sort = index_after_sort[index_after_sort != ID][:topN]  # Exclude the input prompt
    print('input Sr. No: ', ID)
    print('input prompt: ', df['prompt'][ID])
    print('input image')
    display(df['image'][ID])

    for i in index_after_sort:
        print('Recommended Sr. No: ', i)
        print('Recommended prompt: ', df['prompt'][i])
        print('Recommended image')
        display(df['image'][i])

# "clustering_coefficient" code
import networkx as nx

def create_graph(correlation_matrix, threshold):
    G = nx.Graph()
    for i in range(len(correlation_matrix)):
        for j in range(i+1, len(correlation_matrix)):
            if correlation_matrix[i][j] >= threshold:
                G.add_edge(i, j, weight=correlation_matrix[i][j])
    return G

def clustering_coefficient(correlation_matrix, threshold):
    G = create_graph(correlation_matrix, threshold)
    avg_clustering_coefficient = nx.average_clustering(G)
    return avg_clustering_coefficient

# plot "spring_layout" GRAPH
import networkx as nx
import matplotlib.pyplot as plt

def draw_graph_spring(correlation_matrix, threshold):
    G = nx.Graph()

    for i in range(len(correlation_matrix)):
        for j in range(i+1, len(correlation_matrix)):
            if correlation_matrix[i][j] >= threshold:
                G.add_edge(i, j, weight=correlation_matrix[i][j])

    pos = nx.spring_layout(G, seed=42, scale=5)
    nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray', node_size=1000, font_size=8)
    
    # Draw edges with transparency to better visualize connections
    edge_labels = nx.get_edge_attributes(G, 'weight')
    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8, alpha=0.5)
    plt.show()

# "kamada_kawai_layout" GRAPH
import networkx as nx
import matplotlib.pyplot as plt

def draw_graph_Kamada_Kawai(correlation_matrix, threshold):
    G = nx.Graph()

    for i in range(len(correlation_matrix)):
        for j in range(i+1, len(correlation_matrix)):
            if correlation_matrix[i][j] >= threshold:
                G.add_edge(i, j, weight=correlation_matrix[i][j])

    # Use the Kamada-Kawai path-length cost function for the layout
    pos = nx.kamada_kawai_layout(G, scale=5)
    
    nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray', node_size=1000, font_size=8)
    
    # Draw edges with transparency to better visualize connections
    edge_labels = nx.get_edge_attributes(G, 'weight')
    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8, alpha=0.5)
    plt.show()

# "Circular_layout" GRAPH
import networkx as nx
import matplotlib.pyplot as plt

def draw_graph_circular(correlation_matrix, threshold):
    G = nx.Graph()

    for i in range(len(correlation_matrix)):
        for j in range(i+1, len(correlation_matrix)):
            if correlation_matrix[i][j] >= threshold:
                G.add_edge(i, j, weight=correlation_matrix[i][j])

    pos = nx.circular_layout(G)
    
    nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray', node_size=1000, font_size=8)
    
    edge_labels = nx.get_edge_attributes(G, 'weight')
    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8, alpha=0.5)
    
    plt.show()

# Import Libraries
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity, cosine_distances
import gensim.downloader as api
from transformers import CLIPProcessor, CLIPModel
from PIL import Image

""""Tf_sim" represents the cosine similarity between the text data based on the Term Frequency-Inverse Document Frequency (TF-IDF) representation.

"CV_sim" represents the cosine similarity based on the CountVectorizer representation (Bag of Words). 

They are both similarity measures based on text data, but they use different representations.

# Model 1.1: "CV_sim" represents the cosine similarity based on the CountVectorizer representation (Bag of Words).

# Model 1.1: CV_sim Model
"""

import random
from sklearn.feature_extraction.text import TfidfVectorizer

# Bag of words
vectorizer = CountVectorizer()
bag_of_words = vectorizer.fit_transform(df['prompt'])
CV_sim = cosine_similarity(bag_of_words)
CV_sim

similarity_matrix = CV_sim
threshold = 0.7
top_N = 3
example = 712
print("Average clustering coefficient:", clustering_coefficient(similarity_matrix, threshold))
print("graph_spring_Layout")
#draw_graph_spring(similarity_matrix, threshold)
print("graph_Kamada_Kawai_Layout")
#draw_graph_Kamada_Kawai(similarity_matrix, threshold)
print("graph_circular_Layout")
#draw_graph_circular(similarity_matrix, threshold)
print("Top N recoemmendations")
similar_prompts(top_N, similarity_matrix, example)

# Save graph as gexf file
graph_CV_sim = create_graph(similarity_matrix, threshold)
nx.write_gexf(graph_CV_sim, "graph_CV_sim.gexf")

"""# Model 1.2: "Tf_sim" Term Frequency-Inverse Document Frequency (TF-IDF) Model"""

# TF-IDF
tfidf_vectorizer = TfidfVectorizer()
tfidf_matrix = tfidf_vectorizer.fit_transform(df['prompt'])
Tf_sim = cosine_similarity(tfidf_matrix)
Tf_sim

similarity_matrix = Tf_sim
threshold = 0.7
top_N = 3
example = 712
print("Average clustering coefficient:", clustering_coefficient(similarity_matrix, threshold))
print("graph_spring_Layout")
# draw_graph_spring(similarity_matrix, threshold)
print("graph_Kamada_Kawai_Layout")
#draw_graph_Kamada_Kawai(similarity_matrix, threshold)
print("graph_circular_Layout")
#draw_graph_circular(similarity_matrix, threshold)
print("Top N recoemmendations")
similar_prompts(top_N, similarity_matrix, example)

# Save graph as gexf file
graph_Tf_sim = create_graph(similarity_matrix, threshold)
nx.write_gexf(graph_Tf_sim, "graph_Tf_sim.gexf")

"""# Model 3.1: "word2vec_model" based on Word embeddings and distance metrics"""

import gensim.downloader as api
from sklearn.metrics.pairwise import cosine_similarity

# Model 3.1 - Word embeddings and distance metrics
word2vec_model = api.load("word2vec-google-news-300")
df['embedding'] = df['prompt'].apply(lambda prompt: np.mean([word2vec_model[word] for word in prompt.split() if word in word2vec_model], axis=0))
# Filter out any empty embeddings
df = df[df['embedding'].apply(lambda x: x.shape[0] == 300)]
# Calculate cosine similarity
word2vec_sim = cosine_similarity(np.vstack(df['embedding'].values))
word2vec_sim

similarity_matrix = word2vec_sim
threshold = 0.7
top_N = 3
example = 712
print("Average clustering coefficient:", clustering_coefficient(similarity_matrix, threshold))
print("graph_spring_Layout")
#draw_graph_spring(similarity_matrix, threshold)
print("graph_Kamada_Kawai_Layout")
#draw_graph_Kamada_Kawai(similarity_matrix, threshold)
print("graph_circular_Layout")
#draw_graph_circular(similarity_matrix, threshold)
print("Top N recoemmendations")
similar_prompts(top_N, similarity_matrix, example)


# Save graph as gexf file
graph_word2vec_sim = create_graph(similarity_matrix, threshold)
nx.write_gexf(graph_word2vec_sim, "graph_word2vec_sim.gexf")

"""# Model 3.2: "glove_model"
"""

# Model 3.2: "glove_model"
import gensim.downloader as api
from sklearn.metrics.pairwise import cosine_similarity

# Step 3: Model 3 - Word embeddings and distance metrics
glove_model = api.load("glove-wiki-gigaword-300")

def mean_embedding(prompt):
    embeddings = [glove_model[word] for word in prompt.split() if word in glove_model]
    return np.mean(embeddings, axis=0) if embeddings else None

df['embedding'] = df['prompt'].apply(mean_embedding)
# Filter out any empty embeddings
df = df[df['embedding'].notna()]
# Calculate cosine similarity
glove_model_sim = cosine_similarity(np.vstack(df['embedding'].values))
glove_model_sim

similarity_matrix = glove_model_sim
threshold = 0.7
top_N = 3
example = 712
print("Average clustering coefficient:", clustering_coefficient(similarity_matrix, threshold))
print("graph_spring_Layout")
#draw_graph_spring(similarity_matrix, threshold)
print("graph_Kamada_Kawai_Layout")
#draw_graph_Kamada_Kawai(similarity_matrix, threshold)
print("graph_circular_Layout")
#draw_graph_circular(similarity_matrix, threshold)
print("Top N recoemmendations")
similar_prompts(top_N, similarity_matrix, example)

# Save graph as gexf file
graph_glove_model_sim = create_graph(similarity_matrix, threshold)
nx.write_gexf(graph_glove_model_sim, "graph_glove_model_sim.gexf")

"""# Model 3.3: "bert" model"""

# Model 3.3: "bert" model

# To compute the cosine similarity matrix for BERT embeddings, you need to first tokenize the prompts and then obtain embeddings from the BERT model. Here's the updated code:
from transformers import AutoTokenizer, AutoModel
import torch
from sklearn.metrics.pairwise import cosine_similarity

# Load tokenizer and model
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
bert_model = AutoModel.from_pretrained("bert-base-uncased")

# Function to get BERT embeddings
def get_bert_embedding(prompts):
    inputs = tokenizer(prompts, return_tensors="pt", max_length=512, truncation=True, padding="max_length")
    outputs = bert_model(**inputs)
    return outputs.last_hidden_state[:, 0, :].detach().numpy()

# Process prompts in batches
batch_size = 64
embeddings = []

for i in range(0, len(df), batch_size):
    batch = df['prompt'][i:i+batch_size].tolist()
    embeddings.extend(get_bert_embedding(batch))

df['embedding'] = embeddings

# Filter out any empty embeddings
df = df[df['embedding'].apply(lambda x: x.shape[0] == 768)]

# Calculate cosine similarity
bert_model_sim = cosine_similarity(np.vstack(df['embedding'].values))
bert_model_sim

# This code loads the BERT tokenizer and model using the from_pretrained method, defines a function get_bert_embedding to obtain BERT embeddings, and computes the cosine similarity matrix, storing it in the variable bert_model_sim.

similarity_matrix = bert_model_sim
threshold = 0.7
top_N = 3
example = 712
print("Average clustering coefficient:", clustering_coefficient(similarity_matrix, threshold))

similarity_matrix = bert_model_sim
threshold = 0.7
top_N = 3
example = 712
print("Average clustering coefficient:", clustering_coefficient(similarity_matrix, threshold))
#print("graph_spring_Layout")
#draw_graph_spring(similarity_matrix, threshold)
print("graph_Kamada_Kawai_Layout")
#draw_graph_Kamada_Kawai(similarity_matrix, threshold)
print("graph_circular_Layout")
#draw_graph_circular(similarity_matrix, threshold)
print("Top N recoemmendations")
similar_prompts(top_N, similarity_matrix, example)

# Create Graph
graph_bert_model_sim = create_graph(similarity_matrix, threshold)

# Create Graph
threshold = 0.9
graph_bert_model_sim = create_graph(similarity_matrix, threshold)
# Save graph as GEXF file
nx.write_gexf(graph_bert_model_sim, "graph_bert_model_sim.gexf")

import os

gexf_filename = "graph_bert_model_sim.gexf"
file_path = os.path.join(os.getcwd(), gexf_filename)

print(f"The file path of the GEXF file is: {file_path}")

"""# Model 4: Object detection using CLIP"""

df['image'][712]

! pip install torchvision

# Model 4: Object detection using CLIP
from transformers import CLIPProcessor, CLIPModel
import torch
from sklearn.metrics.pairwise import cosine_similarity

clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")

from PIL import Image
import torchvision.transforms as transforms

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),
])

def image_to_clip_features(image):
    if not isinstance(image, Image.Image):
        return np.zeros(512)
    
    try:
        image_tensor = transform(image).unsqueeze(0)
        
        with torch.no_grad():
            outputs = clip_model.get_image_features(image_tensor)
            features = outputs.cpu().numpy()

        # Check if all extracted features are zero
        if np.all(features[0] == 0):
            print(f"This is an issue: All extracted features for the image are zero.")
        return features[0]
    except Exception as e:
        print(f"Error processing image: {e}")
        return np.zeros(512)


# Apply the function to the 'image' column
df['clip_features'] = df['image'].apply(image_to_clip_features)

CLIP_sim = cosine_similarity(np.vstack(df['clip_features'].values))
CLIP_sim

# Save graph as GEXF file
threshold = 0.9
CLIP_sim = create_graph(similarity_matrix, threshold)
nx.write_gexf(graph_CLIP_sim, "graph_CLIP_sim.gexf")

import os

gexf_filename = "graph_CLIP_sim.gexf"
file_path = os.path.join(os.getcwd(), gexf_filename)

print(f"The file path of the GEXF file is: {file_path}")

similarity_matrix = CLIP_sim
threshold = 0.7
top_N = 3
example = 712
print("Average clustering coefficient:", clustering_coefficient(similarity_matrix, threshold))
print("graph_spring_Layout")
#draw_graph_spring(similarity_matrix, threshold)
print("graph_Kamada_Kawai_Layout")
#draw_graph_Kamada_Kawai(similarity_matrix, threshold)
print("graph_circular_Layout")
#draw_graph_circular(similarity_matrix, threshold)
print("Top N recoemmendations")
similar_prompts(top_N, similarity_matrix, example)

# Save graph as GEXF file
graph_CLIP_sim = create_graph(similarity_matrix, threshold)
nx.write_gexf(graph_CLIP_sim, "graph_CLIP_sim.gexf")

"""#Final: Ensemble Model"""

# Step 5: Combine similarity scores and recommend prompts
import numpy as np

# Combine the similarity matrices
ensemble_sim = (np.array(bert_model_sim) + np.array(CLIP_sim)) / 2

threshold = 0.9
# Create graph for the ensemble model
ensemble_BERT_CLIP_sim = create_graph(ensemble_sim, threshold)

# Save graph as GEXF file
nx.write_gexf(ensemble_BERT_CLIP_sim, "ensemble_BERT_CLIP_sim.gexf")

"""Model 5) NLP entity recognition and refined recommendations:
-- Use NLP libraries like Spacy or NLTK to process the prompt text and extract entities (e.g., using BIOES or other entity recognition models).

-- Encode these entities as features, and compute the pairwise distances between the input prompt and all other prompts using a distance metric.
-- Combine these distance scores with the similarity scores from one of the previous models (e.g., Model 3) using a weighted average.
-- Recommend the prompts with the highest combined scores.
Python libraries: Spacy, NLTK

"""